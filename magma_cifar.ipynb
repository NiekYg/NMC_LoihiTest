{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2182797d-3cc3-40a3-9b5d-6487a22c80a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lava.magma.core.run_configs import Loihi2HwCfg\n",
    "from lava.magma.core.run_conditions import RunSteps\n",
    "from lava.proc.lif.process import LIF\n",
    "from lava.proc.dense.process import Dense\n",
    "from lava.magma.compiler.subcompilers.nc.ncproc_compiler import CompilerOptions\n",
    "from lava.utils.profiler import Profiler\n",
    "\n",
    "np.set_printoptions(linewidth=110)  # Increase the line lenght of output cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ba735f-d6f1-4227-b60c-44611472d1df",
   "metadata": {},
   "source": [
    "## Version 1: running without transformation to spikes (leads to kernel dying)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "010d7606-8e32-4643-bc8f-99df114edee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npz_frames(file_name: str) -> np.ndarray:\n",
    "    '''\n",
    "    :param file_name: path of the npz file that saves the frames\n",
    "    :type file_name: str\n",
    "    :return: frames\n",
    "    :rtype: np.ndarray\n",
    "    '''\n",
    "    return np.load(file_name, allow_pickle=True)['frames'].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bda5d254-94ee-45ad-ba09-9b2e524745fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CIFAR_DVS_dataset():\n",
    "    dataset =  datasets.DatasetFolder('cifar_project/CIFAR/frames_number_10_split_by_number', loader = load_npz_frames, extensions=('.npz', '.npy'))\n",
    "    training_set, testing_validation_set = split_to_train_test_set(0.995, dataset, 10)\n",
    "    #testing_validation_set = torch.load(\"cifar_dvs_dataset_mini_mini_reshaped.pt\")\n",
    "    return testing_validation_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "778c7718-f533-41a0-9ac9-90513f3fb94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b0bb076-69d3-47b7-a1cc-599f6b31f933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "cifar_data_reshaped = CIFAR_DVS_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e95c492d-5a86-4636-84f1-83f8f620c520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "trained_weights_path = os.path.join('.', 'network.npy')\n",
    "\n",
    "real_path_trained_wgts = os.path.realpath(trained_weights_path)\n",
    "\n",
    "wb_list = np.load(real_path_trained_wgts, encoding='latin1', allow_pickle=True).item()\n",
    "w0 = wb_list['blocks.0.synapse.weight_v'].astype(np.int32)\n",
    "w0_shape = np.shape(w0)\n",
    "w0 = w0.reshape((w0_shape[0], w0_shape[1]))\n",
    "w1 = wb_list['blocks.1.synapse.weight_v'].astype(np.int32)\n",
    "w1_shape = np.shape(w1)\n",
    "w1 = w1.reshape((w1_shape[0], w1_shape[1]))\n",
    "w2 = wb_list['blocks.2.synapse.weight_v'].astype(np.int32)\n",
    "w2_shape = np.shape(w2)\n",
    "w2 = w2.reshape((w2_shape[0], w2_shape[1]))\n",
    "u0 = wb_list['blocks.0.neuron.current_decay'].astype(np.int32)\n",
    "u1 = wb_list['blocks.1.neuron.current_decay'].astype(np.int32)\n",
    "u2 = wb_list['blocks.2.neuron.current_decay'].astype(np.int32)\n",
    "\n",
    "v0 = wb_list['blocks.0.neuron.voltage_decay'].astype(np.int32) \n",
    "v1 = wb_list['blocks.1.neuron.voltage_decay'].astype(np.int32) \n",
    "v2 = wb_list['blocks.2.neuron.voltage_decay'].astype(np.int32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92a1e6e-21cb-4052-80ee-8f1c2056749b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lava.proc.io.dataloader import SpikeDataloader \n",
    "lif_src = SpikeDataloader(dataset = cifar_data_reshaped)\n",
    "dense = Dense(weights=w0)\n",
    "lif_dest = LIF(shape=(512,), vth = 1.25, dv = v0, du = u0)\n",
    "dense1 = Dense(weights=w1)\n",
    "lif_dest_1 = LIF(shape=(512,), vth = 1.25, dv = v1, du = u1)   \n",
    "dense2 = Dense(weights=w2)\n",
    "lif_dest_2 = LIF(shape=(10,), vth = 1.25, dv = v2, du = u2)        \n",
    "# Connect the OutPort of lif_src to the InPort of dense.\n",
    "lif_src.s_out.connect(dense.s_in)\n",
    "dense.a_out.connect(lif_dest.a_in)\n",
    "lif_dest.s_out.connect(dense1.s_in)\n",
    "# Connect the OutPort of dense to the InPort of lif_dst.\n",
    "dense1.a_out.connect(lif_dest_1.a_in)\n",
    "lif_dest_1.s_out.connect(dense2.s_in)\n",
    "# Connect the OutPort of dense to the InPort of lif_dst.\n",
    "dense2.a_out.connect(lif_dest_2.a_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adab1916-1792-447d-a5e2-4c068b304054",
   "metadata": {},
   "source": [
    "## Version 2: Transformation into spikes (leads to source destination error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0e646414-bd95-49fb-a583-7d12ee641db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toSpikeTensor(event, emptyTensor, samplingTime=1, randomShift=False, binningMode='OR'):\n",
    "  event_dim = 2\n",
    "  if randomShift is True:\n",
    "    tSt = np.random.randint(\n",
    "      max(\n",
    "        int(event['t'].min() / samplingTime),\n",
    "        int(event['t'].max() / samplingTime) - emptyTensor.shape[3],\n",
    "        emptyTensor.shape[3] - int(event['t'].max() / samplingTime),\n",
    "        1,\n",
    "      )\n",
    "    )\n",
    "  else:\n",
    "    tSt = 0\n",
    "\n",
    "  xEvent = np.round(event['x']).astype(int)\n",
    "  pEvent = np.round(event['p']).astype(int)\n",
    "  tEvent = np.round(event['t']/samplingTime).astype(int) - tSt\n",
    "\n",
    "  if event_dim == 1:\n",
    "    validInd = np.argwhere((xEvent < emptyTensor.shape[2]) &\n",
    "                  (pEvent < emptyTensor.shape[0]) &\n",
    "                  (tEvent < emptyTensor.shape[3]) &\n",
    "                  (xEvent >= 0) &\n",
    "                  (pEvent >= 0) &\n",
    "                  (tEvent >= 0))\n",
    "    if binningMode.upper() == 'OR':\n",
    "      emptyTensor[pEvent[validInd],\n",
    "            0,\n",
    "            xEvent[validInd],\n",
    "            tEvent[validInd]] = 1/samplingTime\n",
    "    elif binningMode.upper() == 'SUM':\n",
    "      emptyTensor[pEvent[validInd],\n",
    "            0,\n",
    "            xEvent[validInd],\n",
    "            tEvent[validInd]] += 1/samplingTime\n",
    "    else:\n",
    "      raise Exception('Unsupported binningMode. It was {}'.format(binningMode))\n",
    "\n",
    "  elif  event_dim == 2:\n",
    "    yEvent = np.round(event['y']).astype(int)\n",
    "    validInd = np.argwhere((xEvent < emptyTensor.shape[2]) &\n",
    "                  (yEvent < emptyTensor.shape[1]) &\n",
    "                  (pEvent < emptyTensor.shape[0]) &\n",
    "                  (tEvent < emptyTensor.shape[3]) &\n",
    "                  (xEvent >= 0) &\n",
    "                  (yEvent >= 0) &\n",
    "                  (pEvent >= 0) &\n",
    "                  (tEvent >= 0))\n",
    "\n",
    "    if binningMode.upper() == 'OR':\n",
    "      emptyTensor[pEvent[validInd],\n",
    "            yEvent[validInd],\n",
    "            xEvent[validInd],\n",
    "            tEvent[validInd]] = 1/samplingTime\n",
    "    elif binningMode.upper() == 'SUM':\n",
    "      emptyTensor[pEvent[validInd],\n",
    "            yEvent[validInd],\n",
    "            xEvent[validInd],\n",
    "            tEvent[validInd]] += 1/samplingTime\n",
    "    else:\n",
    "      raise Exception('Unsupported binningMode. It was {}'.format(binningMode))\n",
    "\n",
    "  return emptyTensor\n",
    "\n",
    "\n",
    "\n",
    "def toSpikeArray(event, samplingTime=1, dim=None):\n",
    "  event_dim = 1\n",
    "  if 'y' in event.keys():\n",
    "\t\t\tevent_dim = 2\n",
    "  if event_dim == 1:\n",
    "    if dim is None: dim = ( np.round(max(event['p'])+1).astype(int),\n",
    "                np.round(max(event['x'])+1).astype(int),\n",
    "                np.round(max(event['t'])/samplingTime+1).astype(int) )\n",
    "    frame = np.zeros((dim[0], 1, dim[1], dim[2]))\n",
    "  elif event_dim == 2:\n",
    "    if dim is None: dim = ( np.round(max(event['p'])+1).astype(int),\n",
    "                np.round(max(event['y'])+1).astype(int),\n",
    "                np.round(max(event['x'])+1).astype(int),\n",
    "                np.round(max(event['t'])/samplingTime+1).astype(int) )\n",
    "    # using 200 here instead of dim[3]\n",
    "    frame = np.zeros((dim[0], dim[1], dim[2], dim[3]))\n",
    "  return toSpikeTensor(event, frame, samplingTime).reshape(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bd7020c4-43c3-4c7f-9d97-8701fcb303bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class SpikeDataset(Dataset):\n",
    "    def __init__(self, root_folder, transform=None):\n",
    "        self.root_folder = root_folder\n",
    "        self.transform = transform\n",
    "        self.classes, self.class_to_idx = self._find_classes()\n",
    "        self.samples = self._make_dataset()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path, target = self.samples[idx]\n",
    "        data = np.load(file_path)\n",
    "        arrays = {key: data[key] for key in data.keys()}\n",
    "        spike = toSpikeArray(arrays,samplingTime = 100000)\n",
    "        spike_reshaped = np.moveaxis(spike, 1, -1)\n",
    "        spike_reshaped = np.moveaxis(spike_reshaped, 1, -1)\n",
    "        # Perform average pooling only along the last two dimensions (20x20)\n",
    "        spike_pooled = F.avg_pool2d(torch.tensor(spike_reshaped), kernel_size=7, stride=7, padding=0).numpy()\n",
    "\n",
    "        # Reshape back to the original shape\n",
    "        spike_pooled = np.moveaxis(spike_pooled, -1, 1)\n",
    "        spike_pooled = np.moveaxis(spike_pooled, -1, 1)\n",
    "        \n",
    "        return spike_pooled.reshape(-1, np.shape(spike_pooled)[3]), target\n",
    "\n",
    "    def _find_classes(self):\n",
    "        # Find the class folders in your dataset\n",
    "        classes = [d for d in os.listdir(self.root_folder) if os.path.isdir(os.path.join(self.root_folder, d))]\n",
    "        classes.sort()\n",
    "        class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "        return classes, class_to_idx\n",
    "\n",
    "    def _make_dataset(self):\n",
    "        # Create a list of file paths and their corresponding labels\n",
    "        samples = []\n",
    "        for target_class in self.classes:\n",
    "            class_index = self.class_to_idx[target_class]\n",
    "            target_dir = os.path.join(self.root_folder, target_class)\n",
    "            for root, _, fnames in sorted(os.walk(target_dir)):\n",
    "                for fname in fnames:\n",
    "                    path = os.path.join(root, fname)\n",
    "                    item = (path, class_index)\n",
    "                    samples.append(item)\n",
    "        return samples\n",
    "\n",
    "root_folder = \"events_np/content/events_np/content/CIFAR/events_np\"\n",
    "spike_dataset = SpikeDataset(root_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "24aba190-1b83-42c5-9540-14f65673affb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lava.proc.io.dataloader import SpikeDataloader, PySpikeModelFloat\n",
    "lif_src = SpikeDataloader(dataset = spike_dataset)\n",
    "dense = Dense(weights=np.ones((512, 648)))\n",
    "lif_dest = LIF(shape=(512,))\n",
    "dense1 = Dense(weights=np.ones((512, 512)))\n",
    "lif_dest_1 = LIF(shape=(512,))   \n",
    "dense2 = Dense(weights=np.ones((10,512)))\n",
    "lif_dest_2 = LIF(shape=(10,))        \n",
    "# Connect the OutPort of lif_src to the InPort of dense.\n",
    "lif_src.s_out.connect(dense.s_in)\n",
    "dense.a_out.connect(lif_dest.a_in)\n",
    "lif_dest.s_out.connect(dense1.s_in)\n",
    "# Connect the OutPort of dense to the InPort of lif_dst.\n",
    "dense1.a_out.connect(lif_dest_1.a_in)\n",
    "lif_dest_1.s_out.connect(dense2.s_in)\n",
    "# Connect the OutPort of dense to the InPort of lif_dst.\n",
    "dense2.a_out.connect(lif_dest_2.a_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b62c614-053d-4ede-8854-03c1e965c41c",
   "metadata": {},
   "source": [
    "### Configure profiling tools\n",
    "\n",
    "The profiler needs as initialization the run configuration as parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e129e604-3b8e-4387-bff9-b5ec3dd30b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 3\n",
    "run_config = Loihi2HwCfg()\n",
    "profiler = Profiler.init(run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07efcf7b-4ff2-459b-a8a6-fe00b9407007",
   "metadata": {},
   "source": [
    "Afterwards we configure an execution time probe. Configuring an energy, activity and memory probe additionaly or extra also works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "71844e8c-eed7-405c-a980-d13d3e75def6",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler.execution_time_probe(num_steps=num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f037c7b6-5bc3-49c4-9558-8907cff64fdf",
   "metadata": {},
   "source": [
    "### Run the network\n",
    "\n",
    "The network will run for 100 time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c26041b9-f7f7-441a-ba2f-7e4606885adf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per core distribution:\n",
      "----------------------------------------------------------------\n",
      "| AxonIn |NeuronGr| Neurons|Synapses| AxonMap| AxonMem|  Cores |\n",
      "|--------------------------------------------------------------|\n",
      "|     512|       1|      10|    1536|      10|       0|       1|\n",
      "|     512|       1|      73|    7899|      73|       0|       7|\n",
      "|     648|       1|      51|    7128|      51|       0|      10|\n",
      "|--------------------------------------------------------------|\n",
      "| Total                                               |      18|\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "No support for (source, destination) pairs of type '(PySpikeModelFixed, NcModelDense)' yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Execute Process lif_src and all Processes connected to it (dense, lif_dest). \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mlif_src\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcondition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRunSteps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_steps\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#print(\"Sent spikes:\", lif_src.s_out, \"\\nReceived spikes:\", lif_dest_1.s_out)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#lif_src.stop()\u001b[39;00m\n",
      "File \u001b[0;32m~/lava/lava_nx_env/lib/python3.8/site-packages/lava/magma/core/process/process.py:350\u001b[0m, in \u001b[0;36mAbstractProcess.run\u001b[0;34m(self, condition, run_cfg, compile_config)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m run_cfg:\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe Processes that are to be executed have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    347\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot been compiled yet. This requires that a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    348\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunConfig is passed to the run() method.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 350\u001b[0m executable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_cfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_runtime \u001b[38;5;241m=\u001b[39m Runtime(executable,\n\u001b[1;32m    352\u001b[0m                         ActorType\u001b[38;5;241m.\u001b[39mMultiProcessing,\n\u001b[1;32m    353\u001b[0m                         loglevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_config\u001b[38;5;241m.\u001b[39mlevel)\n\u001b[1;32m    354\u001b[0m executable\u001b[38;5;241m.\u001b[39massign_runtime_to_all_processes(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_runtime)\n",
      "File \u001b[0;32m~/lava/lava_nx_env/lib/python3.8/site-packages/lava/magma/core/process/process.py:376\u001b[0m, in \u001b[0;36mAbstractProcess.compile\u001b[0;34m(self, run_cfg, compile_config)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlava\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmagma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompiler\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompiler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Compiler\n\u001b[1;32m    375\u001b[0m compiler \u001b[38;5;241m=\u001b[39m Compiler(compile_config, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_config\u001b[38;5;241m.\u001b[39mlevel)\n\u001b[0;32m--> 376\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_cfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/lava/lava_nx_env/lib/python3.8/site-packages/lava/magma/compiler/compiler.py:155\u001b[0m, in \u001b[0;36mCompiler.compile\u001b[0;34m(self, process, run_cfg)\u001b[0m\n\u001b[1;32m    140\u001b[0m sync_domains, node_to_sync_domain_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_sync_domains(\n\u001b[1;32m    141\u001b[0m     proc_groups, run_cfg, node_configs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\n\u001b[1;32m    142\u001b[0m )\n\u001b[1;32m    144\u001b[0m (\n\u001b[1;32m    145\u001b[0m     runtime_service_builders,\n\u001b[1;32m    146\u001b[0m     proc_id_to_runtime_service_id_map,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compile_config,\n\u001b[1;32m    154\u001b[0m )\n\u001b[0;32m--> 155\u001b[0m channel_builders \u001b[38;5;241m=\u001b[39m \u001b[43mChannelBuildersFactory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_channel_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchannel_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compile_config\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m sync_channel_builders \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_sync_channel_builders(\n\u001b[1;32m    159\u001b[0m     runtime_service_builders\n\u001b[1;32m    160\u001b[0m )\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# Package all Builders and NodeConfigs into an Executable.\u001b[39;00m\n",
      "File \u001b[0;32m~/lava/lava_nx_env/lib/python3.8/site-packages/lava/magma/compiler/subcompilers/channel_builders_factory.py:83\u001b[0m, in \u001b[0;36mChannelBuildersFactory.from_channel_map\u001b[0;34m(self, channel_map, compile_config)\u001b[0m\n\u001b[1;32m     79\u001b[0m initializers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_port_initializers(\n\u001b[1;32m     80\u001b[0m     [src_port, dst_port], channel_map\n\u001b[1;32m     81\u001b[0m )\n\u001b[1;32m     82\u001b[0m src_pt_init, dst_pt_init \u001b[38;5;241m=\u001b[39m initializers\n\u001b[0;32m---> 83\u001b[0m ch_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_channel_type_from_ports\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_port\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_port\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ch_type \u001b[38;5;129;01mis\u001b[39;00m ChannelType\u001b[38;5;241m.\u001b[39mCNc \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dst_port, VarPort):\n\u001b[1;32m     85\u001b[0m     address \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_address_for_varport(dst_port)\n",
      "File \u001b[0;32m~/lava/lava_nx_env/lib/python3.8/site-packages/lava/magma/compiler/subcompilers/channel_builders_factory.py:198\u001b[0m, in \u001b[0;36mChannelBuildersFactory._get_channel_type_from_ports\u001b[0;34m(self, src_port, dst_port)\u001b[0m\n\u001b[1;32m    196\u001b[0m src_pm_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_port_process_model_class(src_port)\n\u001b[1;32m    197\u001b[0m dst_pm_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_port_process_model_class(dst_port)\n\u001b[0;32m--> 198\u001b[0m channel_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_channel_type_from_processes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc_pm_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_pm_class\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m channel_type\n",
      "File \u001b[0;32m~/lava/lava_nx_env/lib/python3.8/site-packages/lava/magma/compiler/subcompilers/channel_builders_factory.py:246\u001b[0m, in \u001b[0;36mChannelBuildersFactory._get_channel_type_from_processes\u001b[0;34m(src, dst)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ChannelType\u001b[38;5;241m.\u001b[39mCC\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    247\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for (source, destination) pairs of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdst\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m yet.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    249\u001b[0m     )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: No support for (source, destination) pairs of type '(PySpikeModelFixed, NcModelDense)' yet."
     ]
    }
   ],
   "source": [
    "# Execute Process lif_src and all Processes connected to it (dense, lif_dest). \n",
    "lif_src.run(condition=RunSteps(num_steps=num_steps), run_cfg=run_config)\n",
    "#print(\"Sent spikes:\", lif_src.s_out, \"\\nReceived spikes:\", lif_dest_1.s_out)\n",
    "#lif_src.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95201ad-ece5-4df9-a510-8368307fa25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lif_src.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee322fac-a476-48c4-aac7-2d10dccea60e",
   "metadata": {},
   "source": [
    "## Version 3 (runs forever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223d68a2-58d0-43d0-9196-6aa5f7ca9eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "labels = np.zeros(len(spike_dataset.samples))\n",
    "for i in range(3):\n",
    "    input, label = spike_dataset[i]\n",
    "    inputs.append(input)\n",
    "    labels[i] = label\n",
    "\n",
    "labels = labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caef9e03-3855-49a9-872f-fa5ed4baab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lava.magma.core.process.process import AbstractProcess\n",
    "from lava.magma.core.process.variable import Var\n",
    "from lava.magma.core.process.ports.ports import InPort, OutPort\n",
    "from lava.magma.core.model.sub.model import AbstractSubProcessModel\n",
    "from lava.magma.core.model.py.model import PyLoihiProcessModel\n",
    "\n",
    "# Import ProcessModel ports, data-types\n",
    "from lava.magma.core.model.py.ports import PyInPort, PyOutPort\n",
    "from lava.magma.core.model.py.type import LavaPyType\n",
    "\n",
    "# Import execution protocol and hardware resources\n",
    "from lava.magma.core.sync.protocols.loihi_protocol import LoihiProtocol\n",
    "from lava.magma.core.resources import CPU\n",
    "\n",
    "# Import decorators\n",
    "from lava.magma.core.decorator import implements, requires\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lava.magma.core.run_configs import Loihi2HwCfg\n",
    "from lava.magma.core.run_conditions import RunSteps\n",
    "from lava.proc.lif.process import LIF\n",
    "from lava.proc.dense.process import Dense\n",
    "from lava.magma.compiler.subcompilers.nc.ncproc_compiler import CompilerOptions\n",
    "from lava.utils.profiler import Profiler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3c794f-1a13-4f47-8f06-fedf3f6b7201",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class OutputProcess(AbstractProcess):\n",
    "    def __init__(self, num_images):\n",
    "        super().__init__()\n",
    "        shape = (10,)\n",
    "        \n",
    "        # Creating Vars, InPorts and OutPorts (each process has these!)\n",
    "        \n",
    "        self.spikes_in = InPort(shape=shape)\n",
    "        self.label_in = InPort(shape=(1,))\n",
    "        \n",
    "        self.num_images = Var(shape=(1,), init=num_images)\n",
    "        # Place for acculumating spikes over the time period\n",
    "        self.spikes_accum = Var(shape=shape)\n",
    "        # Each image has 300 timepoints in the training data\n",
    "        self.num_steps_per_image = Var(shape=(1,), init=300)\n",
    "        self.pred_labels = Var(shape=(num_images,))\n",
    "        # Labels for the ground truth\n",
    "        self.gt_labels = Var(shape=(num_images,))\n",
    "\n",
    "# Feeds the input to the model.\n",
    "\n",
    "class InputProcess(AbstractProcess):\n",
    "    def __init__(self, num_images, num_steps_per_image):\n",
    "        super().__init__()\n",
    "        shape = (648,)\n",
    "\n",
    "        # OutPorts\n",
    "        self.spikes_out = OutPort(shape=shape)\n",
    "        self.label_out = OutPort(shape=(1,))\n",
    "\n",
    "        # Vars\n",
    "        self.num_images = Var(shape=(1,), init=num_images)\n",
    "        self.num_steps_per_image = Var(shape=(1,), init=num_steps_per_image)\n",
    "        self.input_img = Var(shape=shape+(300,))\n",
    "        self.ground_truth_label = Var(shape=(1,))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84cc353-dddd-4463-862c-3c5ed2a257b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output ProcessModel\n",
    "\n",
    "@implements(proc=OutputProcess, protocol=LoihiProtocol)\n",
    "@requires(CPU)\n",
    "class PyOutputProcessModel(PyLoihiProcessModel):\n",
    "    label_in: PyInPort = LavaPyType(PyInPort.VEC_DENSE, int, precision=32)\n",
    "    spikes_in: PyInPort = LavaPyType(PyInPort.VEC_DENSE, bool, precision=1)\n",
    "    num_images: int = LavaPyType(int, int, precision=32)\n",
    "    spikes_accum: np.ndarray = LavaPyType(np.ndarray, np.int32, precision=32)\n",
    "    num_steps_per_image: int = LavaPyType(int, int, precision=32)\n",
    "    pred_labels: np.ndarray = LavaPyType(np.ndarray, int, precision=32)\n",
    "    gt_labels: np.ndarray = LavaPyType(np.ndarray, int, precision=32)\n",
    "    \n",
    "    def __init__(self, proc_params):\n",
    "        super().__init__(proc_params=proc_params)\n",
    "        self.current_img_id = 0 # Used to iterate through examples\n",
    "        \n",
    "    def post_guard(self):\n",
    "        ''' Used during PostManagement, determines if an image\n",
    "            has just finished being passed through'''\n",
    "        return self.time_step % self.num_steps_per_image == 0 and \\\n",
    "                self.time_step > 1\n",
    "\n",
    "    def run_post_mgmt(self):\n",
    "        ''' Function executed after post_guard returns True'''\n",
    "        # Storing prediction and ground truths\n",
    "        gt_label = self.label_in.recv() \n",
    "        pred_label = np.argmax(self.spikes_accum)\n",
    "        self.gt_labels[self.current_img_id] = gt_label # Indexing into Process Vars\n",
    "        self.pred_labels[self.current_img_id] = pred_label\n",
    "\n",
    "        # Setting up for next image\n",
    "        self.current_img_id += 1\n",
    "        self.spikes_accum = np.zeros_like(self.spikes_accum)\n",
    "\n",
    "    def run_spk(self):\n",
    "        ''' Runs at every timepoint; getting spikes from the forward pass\n",
    "            and accumulating'''\n",
    "        spk_in = self.spikes_in.recv()\n",
    "        self.spikes_accum = self.spikes_accum + spk_in\n",
    "\n",
    "# Input ProcessModel\n",
    "\n",
    "@implements(proc=InputProcess, protocol=LoihiProtocol)\n",
    "@requires(CPU)\n",
    "class PySpikeInputModel(PyLoihiProcessModel):\n",
    "    num_images: int = LavaPyType(int, int, precision=32)\n",
    "    spikes_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, bool, precision=1)\n",
    "    label_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, np.int32,\n",
    "                                      precision=32)\n",
    "    num_steps_per_image: int = LavaPyType(int, int, precision=32)\n",
    "    input_img: np.ndarray = LavaPyType(np.ndarray, int, precision=32)\n",
    "    ground_truth_label: int = LavaPyType(int, int, precision=32)\n",
    "    \n",
    "    def __init__(self, proc_params):\n",
    "        super().__init__(proc_params=proc_params)\n",
    "        self.input_data = mnist_inputs\n",
    "        self.gt_labels = mnist_labels\n",
    "        self.curr_img_id = 0\n",
    "        self.curr_img_time = 0\n",
    "\n",
    "    def post_guard(self):\n",
    "        ''' PostManagement phase guard'''\n",
    "        return self.time_step % self.num_steps_per_image == 1\n",
    "\n",
    "    def run_post_mgmt(self):\n",
    "        ''' Executed when post_guard returns True, i.e. after image \n",
    "            has finished being fed through. '''\n",
    "        # Getting the next image and ground truth \n",
    "        # to feed through\n",
    "        self.input_img = self.input_data[self.curr_img_id].astype(np.int32)\n",
    "        self.ground_truth_label = self.gt_labels[self.curr_img_id]\n",
    "        \n",
    "        self.label_out.send(np.array([self.ground_truth_label]))\n",
    "        self.curr_img_id += 1\n",
    "\n",
    "    def run_spk(self):\n",
    "        ''' Spiking phase, executed at every timepoint '''\n",
    "        # Input dataset already represents spike trains, so we just\n",
    "        # send the next timepoint\n",
    "        print(self.curr_img_time)\n",
    "        self.spikes_out.send(self.input_img[:,self.curr_img_time])\n",
    "        self.curr_img_time += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878c6425-e052-4c66-a6e1-7ab0baad86b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lif_src = InputProcess(num_images, num_steps_per_image)\n",
    "dense = Dense(weights=np.ones((512, 648)))\n",
    "lif_dest = LIF(shape=(512,))\n",
    "dense1 = Dense(weights=np.ones((512, 512)))\n",
    "lif_dest_1 = LIF(shape=(512,))   \n",
    "dense2 = Dense(weights=np.ones((10,512)))\n",
    "lif_dest_2 =  OutputProcess(num_images)       \n",
    "# Connect the OutPort of lif_src to the InPort of dense.\n",
    "lif_src.spikes_out.connect(dense.s_in)\n",
    "dense.a_out.connect(lif_dest.a_in)\n",
    "lif_dest.s_out.connect(dense1.s_in)\n",
    "# Connect the OutPort of dense to the InPort of lif_dst.\n",
    "dense1.a_out.connect(lif_dest_1.a_in)\n",
    "lif_dest_1.s_out.connect(dense2.s_in)\n",
    "# Connect the OutPort of dense to the InPort of lif_dst.\n",
    "dense2.a_out.connect(lif_dest_2.spikes_in)\n",
    "lif_src.label_out.connect(lif_dest_2.label_in)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b692d2ba-250f-462f-96ff-478a94ed619b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running on one test image\n",
    "from lava.magma.core.run_conditions import RunSteps\n",
    "from lava.magma.core.run_configs import Loihi2SimCfg\n",
    "\n",
    "\n",
    "slayer_network.run(\n",
    "    condition=RunSteps(num_steps=num_steps_per_image),\n",
    "    run_cfg=Loihi2SimCfg())\n",
    "\n",
    "ground_truth = output_process.gt_labels.get().astype(np.int32)\n",
    "predictions = output_process.pred_labels.get().astype(np.int32)\n",
    "\n",
    "slayer_network.stop()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14070384-2a0d-4d01-b24f-03ca9fe5936e",
   "metadata": {},
   "source": [
    "### Retrieve measurement results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476d339c-e2d2-42ae-9bf5-f886fac7db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler.execution_time[:21]  # Time series of the execution time per time step in seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d440f48-37f7-4cc1-b809-a3a9e277c031",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total execution time: {np.round(np.sum(profiler.execution_time), 6)} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d1df8d-10a0-427a-9c79-ed02de0c6f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler.plot_execution_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eec0a5b-e736-462f-ae6e-be1a687aa2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Execution time series of spiking phase: {profiler.spiking_time[:5]}\")\n",
    "print(f\"Execution time series of pre-learning management phase: {profiler.pre_lrn_mgtm_time[:5]}\")\n",
    "print(f\"Execution time series of learning phase: {profiler.learning_time[:5]}\")\n",
    "print(f\"Execution time series of  management phase: {profiler.management_time[95:]}\")\n",
    "print(f\"Execution time series of host phase: {profiler.host_time[95:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1073a2f-ba32-4885-8561-b3ca7b713003",
   "metadata": {},
   "source": [
    "### Energy, activity and memory probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c5f93c4-9dd5-4d7a-b9a5-30c262be9b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 10\n",
    "run_config = Loihi2HwCfg()\n",
    "profiler = Profiler.init(run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5f10d3d-9db4-49ad-a4d8-555ff074748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler.energy_probe(num_steps=num_steps)\n",
    "profiler.activity_probe()\n",
    "profiler.memory_probe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e635ee32-c12c-46a4-a59c-72303d8bbfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Process lif_src and all Processes connected to it (dense, lif_dest).\n",
    "lif_src.run(condition=RunSteps(num_steps=num_steps), run_cfg=run_config)\n",
    "lif_src.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e93f16-8297-42f5-9374-8013808bcb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total execution time: {np.round(np.sum(profiler.execution_time), 6)} s\")\n",
    "print(f\"Total power: {np.round(profiler.power, 6)} W\") \n",
    "print(f\"Total energy: {np.round(profiler.energy, 6)} J\")\n",
    "print(f\"Static energy: {np.round(profiler.static_energy, 6)} J\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a46a19-003e-4716-943a-6c2474aa569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler.power_breakdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b20898c-4765-40c6-8124-d87c54aadfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler.energy_breakdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d796988-b21c-4d20-a033-b5e3ff10de7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler.plot_activity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a15399-d998-404f-a029-0424efaca2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler.plot_memory_util()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28e26610-2038-4f84-8dd3-a697a94b99d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simple_lif_with_execution_time_probe(num_steps, t_start=1, t_end=num_steps, buffer_size=2048, dt=1):\n",
    "    # A very simple network of 100 LIF neurons\n",
    "    lif = LIF(shape=(100,), bias_mant=50, bias_exp=6, vth=100)\n",
    "    \n",
    "    run_config = Loihi2HwCfg()\n",
    "    profiler = Profiler.init(run_config)\n",
    "\n",
    "    # Configure an execution time probe\n",
    "    profiler.execution_time_probe(num_steps=num_steps, t_start=t_start, t_end=t_end, buffer_size=buffer_size, dt=dt)\n",
    "\n",
    "    # Run the network\n",
    "    CompilerOptions.verbose = False  # Limited information output from the compiler for presentation\n",
    "    lif.run(condition=RunSteps(num_steps=num_steps), run_cfg=run_config)\n",
    "    lif.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd31ff20-1abd-4831-be02-70644c6cc07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_simple_lif_with_execution_time_probe(num_steps=100)\n",
    "profiler.plot_execution_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75befb78-a100-4970-ac79-7ef79e382867",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_simple_lif_with_execution_time_probe(num_steps=3000)\n",
    "profiler.plot_execution_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e335cc64-406b-4a87-8486-bf9e4a1225a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_simple_lif_with_execution_time_probe(num_steps=100, buffer_size=64)\n",
    "profiler.plot_execution_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d17d156-5ee5-46c9-8288-f32214af2b22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_simple_lif_with_execution_time_probe(num_steps=3000, buffer_size=3500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030594c3-2292-480d-aee0-0e11ea8c121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_simple_lif_with_execution_time_probe(num_steps=3000, buffer_size=1024, dt=3)\n",
    "profiler.plot_execution_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16daf246-4235-446a-8bab-abebfaf1e9ee",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_simple_lif_with_execution_time_probe(num_steps=3000, t_start=2500, t_end=2600, buffer_size=1024, dt=1)\n",
    "profiler.plot_execution_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4001c190-9893-46ed-ae99-d4d0f448dbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simple_lif_with_energy_probe(num_steps, buffer_size=None):\n",
    "    # A very simple network of 100 LIF neurons\n",
    "    lif = LIF(shape=(100,), bias_mant=50, bias_exp=6, vth=1000)\n",
    "    \n",
    "    run_config = Loihi2HwCfg()\n",
    "    profiler = Profiler.init(run_config)\n",
    "\n",
    "    if buffer_size is not None:\n",
    "        # Configure an execution time probe\n",
    "        profiler.execution_time_probe(num_steps=num_steps, t_start=1, t_end=num_steps, buffer_size=buffer_size, dt=1)\n",
    "\n",
    "    # Configure an energy probe\n",
    "    profiler.energy_probe(num_steps=num_steps)\n",
    "\n",
    "    # Run the network\n",
    "    CompilerOptions.verbose = False  # Limited information output from the compiler for presentation\n",
    "    lif.run(condition=RunSteps(num_steps=num_steps), run_cfg=run_config)\n",
    "    lif.stop()\n",
    "    \n",
    "    return profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3f7a32-60ea-4f60-bcf9-775f41fc416a",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler = run_simple_lif_with_energy_probe(num_steps=100)\n",
    "print(f\"Total energy: {profiler.energy} J\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
