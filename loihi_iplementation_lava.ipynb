{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15939a68-435b-4845-aa62-79e59af98351",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lava.src.lib.dl.netx import hdf5\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import typing as ty\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import lava.lib.dl.slayer as slayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "56a6e801-a24f-480c-94a1-676ce54f6dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# from mnist lava tutorial\n",
    "def augment(event):\n",
    "    x_shift = 4\n",
    "    y_shift = 4\n",
    "    theta = 10\n",
    "    xjitter = np.random.randint(2*x_shift) - x_shift\n",
    "    yjitter = np.random.randint(2*y_shift) - y_shift\n",
    "    ajitter = (np.random.rand() - 0.5) * theta / 180 * 3.141592654\n",
    "    sin_theta = np.sin(ajitter)\n",
    "    cos_theta = np.cos(ajitter)\n",
    "    event.x = event.x * cos_theta - event.y * sin_theta + xjitter\n",
    "    event.y = event.x * sin_theta + event.y * cos_theta + yjitter\n",
    "    return event\n",
    "\n",
    "\n",
    "class CIFARDataset(Dataset):\n",
    "    \"\"\"CIFAR dataset method\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str, optional\n",
    "        path of dataset root, by default 'data'\n",
    "    train : bool, optional\n",
    "        train/test flag, by default True\n",
    "    sampling_time : int, optional\n",
    "        sampling time of event data, by default 1\n",
    "    sample_length : int, optional\n",
    "        length of sample data, by default 300\n",
    "    transform : None or lambda or fx-ptr, optional\n",
    "        transformation method. None means no transform. By default Noney.\n",
    "    download : bool, optional\n",
    "        enable/disable automatic download, by default True\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, path='data',\n",
    "        train=True,\n",
    "        sampling_time=20, sample_length=8000,\n",
    "        transform=None, download=True,\n",
    "    ):\n",
    "        super(CIFARDataset, self).__init__()\n",
    "        self.path = path\n",
    "        self.classes, self.class_to_idx = self._find_classes()\n",
    "        if train:\n",
    "            data_path = \"/content/events_np/content/CIFAR/events_np\"\n",
    "\n",
    "\n",
    "        self.samples = self._make_dataset()\n",
    "\n",
    "        self.sampling_time = sampling_time\n",
    "        self.num_time_bins = int(sample_length/sampling_time)\n",
    "        self.transform = transform\n",
    "    def _find_classes(self):\n",
    "        # Find the class folders in your dataset\n",
    "        classes = [d for d in os.listdir(self.path) if os.path.isdir(os.path.join(self.path, d))]\n",
    "        classes.sort()\n",
    "        class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "        return classes, class_to_idx\n",
    "\n",
    "    def _make_dataset(self):\n",
    "        # Create a list of file paths and their corresponding labels\n",
    "        samples = []\n",
    "        for target_class in self.classes:\n",
    "            class_index = self.class_to_idx[target_class]\n",
    "            target_dir = os.path.join(self.path, target_class)\n",
    "            for root, _, fnames in sorted(os.walk(target_dir)):\n",
    "                for fname in fnames:\n",
    "                    path = os.path.join(root, fname)\n",
    "                    item = (path, class_index)\n",
    "                    samples.append(item)\n",
    "        return samples\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        filename, label = self.samples[i]\n",
    "        ev = np.load(filename)\n",
    "        event = slayer.io.Event(t_event = ev['t'], y_event = ev['y'], x_event = ev['x'], c_event = np.zeros_like(ev['x']))\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            event = self.transform(event)\n",
    "\n",
    "        spike = event.fill_tensor(\n",
    "                torch.zeros(2, 128, 128, self.num_time_bins),\n",
    "                sampling_time=self.sampling_time,\n",
    "            )\n",
    "        spike_reshaped = np.moveaxis(np.array(spike), 1, -1)\n",
    "        spike_reshaped = np.moveaxis(spike_reshaped, 1, -1)\n",
    "        # Perform average pooling only along the last two dimensions \n",
    "        spike_pooled = F.avg_pool2d(torch.tensor(spike_reshaped), kernel_size=7, stride=7, padding=0).numpy()\n",
    "\n",
    "        # Reshape back to the original shape\n",
    "        spike_pooled = np.moveaxis(spike_pooled, -1, 1)\n",
    "        spike_pooled = np.moveaxis(spike_pooled, -1, 1)\n",
    "\n",
    "        spike_pooled = spike_pooled.reshape(-1, np.shape(spike_pooled)[3])\n",
    "        spike_pooled =  torch.tensor(np.where(spike_pooled > 0, 1.0, 0.0), dtype=torch.float)\n",
    "        return spike_pooled, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8df4fb04-8a2f-4333-9a10-2b77bcc37950",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = \"events_np/content/events_np/content/CIFAR/events_np\"\n",
    "spike_dataset = CIFARDataset(root_folder,  train=True, transform = augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64e8c368-8c4a-4b48-bdbc-aaa98e8934d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set = torch.load(\"test_set.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c9457a4b-8d0b-4eea-bee0-a33f901f4309",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs = []\n",
    "labels = np.zeros(1000)\n",
    "for i in range(1000): \n",
    "    input, label = testing_set[i]\n",
    "    \n",
    "    inputs.append(input.numpy())\n",
    "    labels[i] = label\n",
    "\n",
    "labels = labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d0c9964c-ac11-4e74-be8f-5d2e295f4cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process primitives, used for creating the structure of the entire \n",
    "# process and connecting all the modules together. ProcessModels\n",
    "# specify the actual technicalities of how everything works,\n",
    "# and these are backend-specific (we deal with this later)\n",
    "\n",
    "from lava.magma.core.process.process import AbstractProcess\n",
    "from lava.magma.core.process.variable import Var\n",
    "from lava.magma.core.process.ports.ports import InPort, OutPort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "eb9089aa-589f-4faa-af56-9e7731000696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes the output of the model and outputs a classification prediction\n",
    "# based on which neuron has the highest spiking rate\n",
    "\n",
    "class OutputProcess(AbstractProcess):\n",
    "    def __init__(self, num_images):\n",
    "        super().__init__()\n",
    "        shape = (10,)\n",
    "        \n",
    "        # Creating Vars, InPorts and OutPorts (each process has these!)\n",
    "        \n",
    "        self.spikes_in = InPort(shape=shape)\n",
    "        self.label_in = InPort(shape=(1,))\n",
    "        \n",
    "        self.num_images = Var(shape=(1,), init=num_images)\n",
    "        # Place for acculumating spikes over the time period\n",
    "        self.spikes_accum = Var(shape=shape)\n",
    "        # Each image has 300 timepoints in the training data\n",
    "        self.num_steps_per_image = Var(shape=(1,), init=400)\n",
    "        self.pred_labels = Var(shape=(num_images,))\n",
    "        # Labels for the ground truth\n",
    "        self.gt_labels = Var(shape=(num_images,))\n",
    "\n",
    "# Feeds the input to the model.\n",
    "\n",
    "class InputProcess(AbstractProcess):\n",
    "    def __init__(self, num_images, num_steps_per_image):\n",
    "        super().__init__()\n",
    "        shape = (648,)\n",
    "\n",
    "        # OutPorts\n",
    "        self.spikes_out = OutPort(shape=shape)\n",
    "        self.label_out = OutPort(shape=(1,))\n",
    "\n",
    "        # Vars\n",
    "        self.num_images = Var(shape=(1,), init=num_images)\n",
    "        self.num_steps_per_image = Var(shape=(1,), init=num_steps_per_image)\n",
    "        self.input_img = Var(shape=shape+(400,))# CHANGEE\n",
    "        print(shape+(1,))\n",
    "        self.ground_truth_label = Var(shape=(1,))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3935ecae-35e6-4e76-af66-9404ba7acc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import parent classes for ProcessModels\n",
    "from lava.magma.core.model.sub.model import AbstractSubProcessModel\n",
    "from lava.magma.core.model.py.model import PyLoihiProcessModel\n",
    "\n",
    "# Import ProcessModel ports, data-types\n",
    "from lava.magma.core.model.py.ports import PyInPort, PyOutPort\n",
    "from lava.magma.core.model.py.type import LavaPyType\n",
    "\n",
    "# Import execution protocol and hardware resources\n",
    "from lava.magma.core.sync.protocols.loihi_protocol import LoihiProtocol\n",
    "from lava.magma.core.resources import CPU, Loihi2NeuroCore\n",
    "\n",
    "# Import decorators\n",
    "from lava.magma.core.decorator import implements, requires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d38079bb-9579-49ae-a670-876c0a4ee033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output ProcessModel\n",
    "\n",
    "@implements(proc=OutputProcess, protocol=LoihiProtocol)\n",
    "@requires(Loihi2NeuroCore)\n",
    "class PyOutputProcessModel(PyLoihiProcessModel):\n",
    "    label_in: PyInPort = LavaPyType(PyInPort.VEC_DENSE, int, precision=32)\n",
    "    spikes_in: PyInPort = LavaPyType(PyInPort.VEC_DENSE, bool, precision=1)\n",
    "    num_images: int = LavaPyType(int, int, precision=32)\n",
    "    spikes_accum: np.ndarray = LavaPyType(np.ndarray, np.int32, precision=32)\n",
    "    num_steps_per_image: int = LavaPyType(int, int, precision=32)\n",
    "    pred_labels: np.ndarray = LavaPyType(np.ndarray, int, precision=32)\n",
    "    gt_labels: np.ndarray = LavaPyType(np.ndarray, int, precision=32)\n",
    "    \n",
    "    def __init__(self, proc_params):\n",
    "        super().__init__(proc_params=proc_params)\n",
    "        self.current_img_id = 0 # Used to iterate through examples\n",
    "        \n",
    "    def post_guard(self):\n",
    "        ''' Used during PostManagement, determines if an image\n",
    "            has just finished being passed through'''\n",
    "        #print(self.time_step)\n",
    "        return self.time_step % self.num_steps_per_image == 0 and \\\n",
    "                self.time_step > 1\n",
    "\n",
    "    def run_post_mgmt(self):\n",
    "        ''' Function executed after post_guard returns True'''\n",
    "        # Storing prediction and ground truths\n",
    "        gt_label = self.label_in.recv() \n",
    "        pred_label = np.argmax(self.spikes_accum)\n",
    "        self.gt_labels[self.current_img_id] = gt_label # Indexing into Process Vars\n",
    "        self.pred_labels[self.current_img_id] = pred_label\n",
    "\n",
    "        # Setting up for next image\n",
    "        self.current_img_id += 1\n",
    "        self.spikes_accum = np.zeros_like(self.spikes_accum)\n",
    "\n",
    "    def run_spk(self):\n",
    "        ''' Runs at every timepoint; getting spikes from the forward pass\n",
    "            and accumulating'''\n",
    "        print(\"there\")\n",
    "        spk_in = self.spikes_in.recv()\n",
    "        print(spk_in.shape)\n",
    "        print(\"gottit\")\n",
    "        self.spikes_accum = self.spikes_accum + spk_in\n",
    "        print(self.spikes_accum.shape)\n",
    "# Input ProcessModel\n",
    "\n",
    "@implements(proc=InputProcess, protocol=LoihiProtocol)\n",
    "@requires(Loihi2NeuroCore)\n",
    "class PySpikeInputModel(PyLoihiProcessModel):\n",
    "    num_images: int = LavaPyType(int, int, precision=32)\n",
    "    spikes_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, bool, precision=1)\n",
    "    label_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, np.int32,\n",
    "                                      precision=32)\n",
    "    num_steps_per_image: int = LavaPyType(int, int, precision=32)\n",
    "    input_img: np.ndarray = LavaPyType(np.ndarray, int, precision=32)\n",
    "    ground_truth_label: int = LavaPyType(int, int, precision=32)\n",
    "    \n",
    "    def __init__(self, proc_params):\n",
    "        super().__init__(proc_params=proc_params)\n",
    "        self.input_data = inputs\n",
    "        self.gt_labels = labels\n",
    "        self.curr_img_id = 0\n",
    "        self.curr_img_time = 0\n",
    "\n",
    "    def post_guard(self):\n",
    "        ''' PostManagement phase guard'''\n",
    "        return self.time_step % self.num_steps_per_image == 1\n",
    "\n",
    "    def run_post_mgmt(self):\n",
    "        ''' Executed when post_guard returns True, i.e. after image \n",
    "            has finished being fed through. '''\n",
    "        \n",
    "        self.input_img = self.input_data[self.curr_img_id]\n",
    "        \n",
    "        self.ground_truth_label = self.gt_labels[self.curr_img_id]\n",
    "        self.label_out.send(np.array([self.ground_truth_label]))\n",
    "        self.curr_img_id += 1\n",
    "        self.curr_img_time = 0\n",
    "\n",
    "    def run_spk(self):\n",
    "        ''' Spiking phase, executed at every timepoint '''\n",
    "        \n",
    "        self.spikes_out.send(self.input_img[:,self.curr_img_time])\n",
    "        \n",
    "        self.curr_img_time += 1\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ca73999b-2495-4cd3-9ebe-e03995e16157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(648, 1)\n",
      "|   Type   |  W  |  H  |  C  | ker | str | pad | dil | grp |delay|\n",
      "|Dense     |    1|    1|  512|     |     |     |     |     |True |\n",
      "|Dense     |    1|    1|  512|     |     |     |     |     |True |\n",
      "|Dense     |    1|    1|   10|     |     |     |     |     |False|\n"
     ]
    }
   ],
   "source": [
    "num_images = 10\n",
    "num_steps_per_image = 4\n",
    "\n",
    "input_process = InputProcess(num_images, num_steps_per_image)\n",
    "# Loading the network as a Process\n",
    "slayer_network = hdf5.Network(net_config='network.net')\n",
    "print(slayer_network)\n",
    "output_process = OutputProcess(num_images)\n",
    "\n",
    "# Connecting Processes\n",
    "input_process.spikes_out.connect(slayer_network.inp)\n",
    "slayer_network.out_layer.out.connect(output_process.spikes_in)\n",
    "# Connecting input and output processes to allow ground truth to flow\n",
    "input_process.label_out.connect(output_process.label_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8d314d-24f6-4a47-95f1-68791933c5dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Running on one test image\n",
    "from lava.magma.core.run_conditions import RunSteps\n",
    "from lava.magma.core.run_configs import Loihi2SimCfg\n",
    "\n",
    "for img_id in range(num_images):\n",
    "    print(f\"\\rCurrent image: {img_id+1}\", end=\"\")\n",
    "    input_process.run(\n",
    "        condition=RunSteps(num_steps=num_steps_per_image),\n",
    "        run_cfg=Loihi2SimCfg(select_sub_proc_model=True))\n",
    "    print(\"done\")\n",
    "ground_truth = output_process.gt_labels.get().astype(np.int32)\n",
    "predictions = output_process.pred_labels.get().astype(np.int32)\n",
    "\n",
    "input_process.stop()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60e5d29-3a34-4417-8450-57f84783e3a9",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57b12b2-294e-4b52-9f36-7be6e92288f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 400\n",
    "run_config = Loihi2HwCfg()\n",
    "profiler = Profiler.init(run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1011a94-2720-48f6-ab30-8d6015ec44bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler.energy_probe(num_steps=num_steps)\n",
    "profiler.activity_probe()\n",
    "profiler.memory_probe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e453bc5-3a80-4f45-ac82-af20720d66cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Process lif_src and all Processes connected to it (dense, lif_dest).\n",
    "lif_src.run(condition=RunSteps(num_steps=num_steps), run_cfg=run_config)\n",
    "lif_src.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab0b1dc-c23c-4ff2-a54d-63873e586087",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total execution time: {np.round(np.sum(profiler.execution_time), 6)} s\")\n",
    "print(f\"Total power: {np.round(profiler.power, 6)} W\") \n",
    "print(f\"Total energy: {np.round(profiler.energy, 6)} J\")\n",
    "print(f\"Static energy: {np.round(profiler.static_energy, 6)} J\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f5c41c-123e-4db4-9e58-344e904a2005",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler.power_breakdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833b67c5-31b6-4147-80e0-0dbec68ff428",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler.energy_breakdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5caadc-bfd3-4ce8-b35e-47ec5b3e9f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total execution time: {np.round(np.sum(profiler.execution_time), 6)} s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
